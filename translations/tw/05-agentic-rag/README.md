# Agentic RAG

本課程提供對「代理型檢索增強生成」（Agentic Retrieval-Augmented Generation, Agentic RAG）的全面概述。這是一種新興的 AI 範式，讓大型語言模型（LLM）在拉取外部資訊的同時，能夠自主規劃下一步行動。與傳統靜態的檢索後閱讀模式不同，Agentic RAG 包含對 LLM 的多次迭代調用，並穿插工具或函數調用以及結構化輸出。系統會評估結果、改進查詢、在必要時調用額外工具，並持續此循環直到找到滿意的解決方案。

## 課程介紹

本課程將涵蓋以下內容：

- **理解 Agentic RAG：** 了解這種 AI 新範式，讓大型語言模型（LLM）在拉取外部數據的同時，能夠自主規劃下一步行動。
- **掌握迭代式製作者-檢查者模式：** 理解 LLM 的迭代調用循環，穿插工具或函數調用以及結構化輸出，旨在提升正確性並處理格式不正確的查詢。
- **探索實際應用場景：** 找出 Agentic RAG 的亮點應用場景，例如以正確性為優先的環境、複雜的數據庫互動以及延伸工作流程。

## 學習目標

完成本課程後，您將能夠：

- **理解 Agentic RAG：** 學習這種新興 AI 範式，讓大型語言模型（LLM）在拉取外部數據的同時，能夠自主規劃下一步行動。
- **迭代式製作者-檢查者模式：** 掌握 LLM 的迭代調用循環，穿插工具或函數調用以及結構化輸出，旨在提升正確性並處理格式不正確的查詢。
- **掌控推理過程：** 理解系統如何自主掌控推理過程，決定解決問題的方法，而不依賴預先定義的路徑。
- **工作流程：** 瞭解代理型模型如何自主決定檢索市場趨勢報告、識別競爭對手數據、關聯內部銷售指標、綜合分析結果並評估策略。
- **迭代循環、工具整合與記憶：** 學習系統如何依賴循環互動模式，跨步驟維持狀態與記憶，避免重複循環並做出明智的決策。
- **處理失敗模式與自我修正：** 探索系統的強大自我修正機制，包括迭代和重新查詢、使用診斷工具以及依靠人類監督。
- **代理的界限：** 理解 Agentic RAG 的限制，聚焦於特定領域的自主性、基礎設施依賴以及對安全框架的遵守。
- **實際應用場景與價值：** 找出 Agentic RAG 的亮點應用場景，例如以正確性為優先的環境、複雜的數據庫互動以及延伸工作流程。
- **治理、透明性與信任：** 學習治理與透明性的重要性，包括可解釋的推理、偏差控制以及人類監督。

## 什麼是 Agentic RAG？

代理型檢索增強生成（Agentic Retrieval-Augmented Generation, Agentic RAG）是一種新興的 AI 範式，讓大型語言模型（LLM）在拉取外部資訊的同時，能夠自主規劃下一步行動。與靜態的檢索後閱讀模式不同，Agentic RAG 包含對 LLM 的多次迭代調用，並穿插工具或函數調用以及結構化輸出。系統會評估結果、改進查詢、在必要時調用額外工具，並持續此循環直到找到滿意的解決方案。

這種迭代的「製作者-檢查者」操作模式能提升正確性，處理結構化數據庫（例如 NL2SQL）中格式不正確的查詢，並確保高品質的結果。系統會主動掌控推理過程，重寫失敗的查詢、選擇不同的檢索方法並整合多種工具，例如 Azure AI Search 的向量檢索、SQL 數據庫或自定義 API，然後再完成答案。代理型系統的獨特之處在於它能自主掌控推理過程，而不是依賴預定義的路徑。

## 定義代理型檢索增強生成（Agentic RAG）

代理型檢索增強生成（Agentic RAG）是一種 AI 開發的新興範式，讓 LLM 不僅能從外部數據來源中拉取資訊，還能自主規劃下一步行動。與靜態的檢索後閱讀模式或精心編排的提示序列不同，Agentic RAG 包含一個迭代循環，穿插工具或函數調用以及結構化輸出。在每個階段，系統會評估已獲得的結果，決定是否改進查詢、調用額外工具，並持續此循環直到達成滿意的解決方案。

這種迭代的「製作者-檢查者」操作模式旨在提升正確性，處理結構化數據庫中格式不正確的查詢（例如 NL2SQL），並確保平衡且高品質的結果。與僅依賴精心設計的提示鏈不同，系統會主動掌控推理過程。它能重寫失敗的查詢、選擇不同的檢索方法，並整合多種工具，例如 Azure AI Search 的向量檢索、SQL 數據庫或自定義 API，然後再完成答案。這樣可以減少對過於複雜的編排框架的需求，僅需一個相對簡單的「LLM 調用 → 工具使用 → LLM 調用 → …」循環即可產生高級且有根據的輸出。

![Agentic RAG 核心循環](../../../translated_images/agentic-rag-core-loop.2224925a913fb3439f518bda61a40096ddf6aa432a11c9b5bba8d0d625e47b79.tw.png)

## 掌控推理過程

讓系統成為「代理型」的關鍵特性是其自主掌控推理過程的能力。傳統的 RAG 實現通常依賴人類預先定義的路徑：例如指定檢索什麼內容以及何時檢索的思路鏈。
但真正的代理型系統能內部決定如何解決問題。它不只是執行腳本，而是基於找到的資訊質量，自主決定步驟的順序。
例如，當被要求制定產品發佈策略時，它不會僅依賴一個列出整個研究和決策工作流程的提示，而是自主決定：

1. 使用 Bing Web Grounding 檢索當前市場趨勢報告。
2. 利用 Azure AI Search 識別相關的競爭對手數據。
3. 使用 Azure SQL Database 關聯歷史內部銷售指標。
4. 通過 Azure OpenAI Service 將調研結果綜合成一個連貫的策略。
5. 評估策略中的漏洞或不一致之處，必要時啟動新一輪的檢索。

所有這些步驟——改進查詢、選擇數據來源、反覆迭代直到「滿意」為止——都是由模型決定的，而非人類預先編寫的腳本。

## 迭代循環、工具整合與記憶

![工具整合架構](../../../translated_images/tool-integration.7b05a923e3278bf1fd2972faa228fb2ac725f166ed084362b031a24bffd26287.tw.png)

代理型系統依賴於一種循環互動模式：

- **初始調用：** 用戶的目標（即用戶提示）被提交給 LLM。
- **工具調用：** 如果模型發現缺少資訊或指令不明確，它會選擇一個工具或檢索方法，例如向量數據庫查詢（例如 Azure AI Search 的混合搜索）或結構化 SQL 調用，來獲取更多上下文。
- **評估與改進：** 在審查返回的數據後，模型決定這些資訊是否足夠。如果不足，它會改進查詢、嘗試不同的工具或調整方法。
- **重複直到滿意：** 此循環持續進行，直到模型認為它擁有足夠的清晰度和證據來提供一個最終的、經過充分推理的回應。
- **記憶與狀態：** 系統會跨步驟維持狀態和記憶，因此可以回憶起之前的嘗試及其結果，避免重複循環並在過程中做出更明智的決策。

隨著時間的推移，這種模式會形成一種逐步深入理解的感覺，讓模型能夠在無需人類不斷干預或重新編寫提示的情況下，完成複雜的多步任務。

## 處理失敗模式與自我修正

Agentic RAG 的自主性還包括強大的自我修正機制。當系統遇到死胡同，例如檢索到無關文件或遇到格式不正確的查詢時，它可以：

- **迭代與重新查詢：** 模型不會返回低價值的回應，而是嘗試新的搜索策略、重寫數據庫查詢或查找替代數據集。
- **使用診斷工具：** 系統可能調用額外的功能來幫助它調試推理步驟或確認檢索數據的正確性。像 Azure AI Tracing 這樣的工具對於實現健全的可觀察性和監控至關重要。
- **依靠人類監督：** 在高風險或多次失敗的場景中，模型可能會標記不確定性並請求人類指導。一旦人類提供了糾正性反饋，模型可以在後續操作中吸收這一教訓。

這種迭代且動態的方法讓模型能夠持續改進，確保它不僅僅是一個「一次性」的系統，而是一個能夠在特定會話中從錯誤中學習的系統。

![自我修正機制](../../../translated_images/self-correction.3d42c31baf4a476bb89313cec58efb196b0e97959c04d7439cc23d27ef1242ac.tw.png)

## 代理的界限

儘管在任務中具備自主性，Agentic RAG 並不等同於通用人工智慧（AGI）。其「代理型」能力被限制在開發者提供的工具、數據來源和政策範圍內。它無法自行創建工具或超越既定的領域邊界，而是擅長動態編排現有資源。

與更高級的 AI 形式相比，其主要差異包括：

1. **特定領域的自主性：** Agentic RAG 系統專注於在已知領域內實現用戶定義的目標，採用查詢重寫或工具選擇等策略來提升結果。
2. **依賴基礎設施：** 系統的能力取決於開發者整合的工具和數據。它無法在沒有人工干預的情況下超越這些邊界。
3. **遵守安全框架：** 道德指導方針、合規規則和業務政策仍然至關重要。代理的自由度始終受到安全措施和監管機制的限制（希望如此？）。

## 實際應用場景與價值

Agentic RAG 在需要迭代改進和高精度的場景中表現尤為突出：

1. **以正確性為優先的環境：** 在合規檢查、法規分析或法律研究中，代理型模型可以反覆驗證事實、諮詢多個來源並重寫查詢，直到產生經過充分審核的答案。
2. **複雜的數據庫互動：** 當處理結構化數據時，查詢可能經常失敗或需要調整，系統可以利用 Azure SQL 或 Microsoft Fabric OneLake 自主改進查詢，確保最終檢索與用戶意圖一致。
3. **延伸工作流程：** 當新的資訊浮現時，長時間運行的會話可能會隨之演變。Agentic RAG 能夠持續整合新數據，並根據對問題空間的進一步了解調整策略。

## 治理、透明性與信任

隨著這些系統在推理上變得更加自主，治理與透明性至關重要：

- **可解釋的推理：** 模型可以提供一個查詢記錄，包括它進行的查詢、諮詢的來源以及它採取的推理步驟。像 Azure AI Content Safety 和 Azure AI Tracing / GenAIOps 這樣的工具有助於保持透明性並減少風險。
- **偏差控制與平衡檢索：** 開發者可以調整檢索策略以確保考慮到平衡且具代表性的數據來源，並定期審核輸出以檢測偏差或偏向模式，這對於使用 Azure Machine Learning 的高級數據科學組織尤其重要。
- **人類監督與合規：** 對於敏感任務，人類審核仍然是必要的。Agentic RAG 不會取代人類在高風險決策中的判斷，而是通過提供經過充分審核的選項來輔助人類。

擁有能夠清楚記錄操作的工具至關重要。否則，調試多步驟過程可能會非常困難。以下是 Literal AI（Chainlit 背後的公司）提供的一個代理運行範例：

![代理運行範例](../../../translated_images/AgentRunExample.27e2df23ad898772d1b3e7a3e3cd4615378e10dfda87ae8f06b4748bf8eea97d.tw.png)

![代理運行範例2](../../../translated_images/AgentRunExample2.c0e8c78b1f2540a641515e60035abcc6a9c5e3688bae143eb6c559dd37cdee9f.tw.png)

## 結論

Agentic RAG 代表了 AI 系統處理複雜數據密集型任務的一種自然演進。通過採用循環互動模式、自主選擇工具並改進查詢直到達到高品質結果，該系統超越了靜態的提示執行，成為一個更具適應性和上下文感知的決策者。儘管仍然受到人類定義的基礎設施和道德準則的約束，這些代理型能力為企業和最終用戶帶來了更豐富、更動態、最終更有用的 AI 互動。

## 其他資源

- 使用 Azure OpenAI Service 實現檢索增強生成（RAG）：學習如何使用您自己的數據與 Azure OpenAI Service。[此 Microsoft Learn 模組提供了實現 RAG 的全面指南](https://learn.microsoft.com/training/modules/use-own-data-azure-openai)
- 使用 Azure AI Foundry 評估生成式 AI 應用：本文涵蓋了在公開數據集上評估和比較模型的方法，包括 [代理型 AI 應用與 RAG 架構](https://learn.microsoft.com/azure/ai-studio/concepts/evaluation-approach-gen-ai)
- [什麼是 Agentic RAG | Weaviate](https://weaviate.io/blog/what-is-agentic-rag)
- [Agentic RAG：代理型檢索增強生成的完整指南 – generation RAG 的新聞](https://ragaboutit.com/agentic-rag-a-complete-guide-to-agent-based-retrieval-augmented-generation/)
- [Agentic RAG：通過查詢重構和自查提升 RAG！Hugging Face 開源 AI 實用手冊](https://huggingface.co/learn/cookbook/agent_rag)
- [為 RAG 添加代理層](https://youtu.be/aQ4yQXeB1Ss?si=2HUqBzHoeB5tR04U)
- [知識助理的未來：Jerry Liu](https://www.youtube.com/watch?v=zeAyuLc_f3Q&t=244s)
- [如何構建 Agentic RAG 系統](https://www.youtube.com/watch?v=AOSjiXP1jmQ)
- [使用 Azure AI Foundry Agent Service 擴展您的 AI 代理](https://ignite.microsoft.com/sessions/BRK102?source=sessions)

### 學術論文

- [2303.17651 Self-Refine: Iterative Refinement with Self-Feedback](https://arxiv.org/abs/2303.17651)
- [2303.11366 Reflexion: Language Agents with Verbal Reinforcement Learning](https://arxiv.org/abs/2303.11366)
- [2305.11738 CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing](https://arxiv.org/abs/2305.11738)

**免責聲明**：  
本文件使用基於機器的人工智能翻譯服務進行翻譯。儘管我們努力確保準確性，但請注意，自動翻譯可能包含錯誤或不準確之處。應以原始語言的文件為權威來源。對於關鍵資訊，建議尋求專業人工翻譯。我們對因使用本翻譯而產生的任何誤解或錯誤解釋不承擔責任。